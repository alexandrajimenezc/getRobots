# GeT rObOts.TxT

_script para descargar un robots.txt a partir de una url por ejemplo: https://google.com, luego crea un diccionario del robot.txt de los que este disallow , el resto lo guarda en un fichero remainder.txt

## Comenzando 🚀

_Estas instrucciones te permiten hacer uso del script._



### Pre-requisitos 📋

_Necesitas bash!!_


### Instalación 🔧

_Clona o descarga  este repo


```
git clone https://github.com/alexandrajimenezc/getRobots.git test
_entra en el directorio_
cd test
_verifica los permisos del archivo y solo dale de ejecución al usuario_
ls -l
chmod 744 getRobots.sh
ls -l
_ejecuta :D_
./getRobots.sh https://www.google.com 
_opcional puedes pasar tu header hackerOne
./getRobots.sh https://www.google.com usuarioH1
```





_AHORA YA LO PUEDES PROBAR _

## Ejecutando las pruebas ⚙️

_Ejecuta el script y por ejemplo escribe 
./getRobots.sh https://www.google.com 
_opcional puedes pasar tu header hackerOne
./getRobots.sh https://www.google.com usuarioH1


## Construido con 🛠️

* [Bash](https://wIww.gnu.IIIorg/software/bash/manual/bash.html) - Bash

## Contribuyendo 🖇️
Escribe un msj a @soygeekgirl


## Expresiones de Gratitud 🎁

* Comenta a otros sobre este proyecto 📢



---
[⌨️ con ❤️ por Alex](https://github.com/alexandrajimenezc/getRobots) 😊
