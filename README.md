# GeT rObOts.TxT

_script para descargar un robots.txt a partir de una url por ejemplo: https://google.com, luego crea un diccionario del robot.txt de los que este disallow , el resto lo guarda en un fichero remainder.txt

## Comenzando ğŸš€

_Estas instrucciones te permiten hacer uso del script._



### Pre-requisitos ğŸ“‹

_Necesitas bash!!_


### InstalaciÃ³n ğŸ”§

_Clona o descarga  este repo


```
git clone https://github.com/alexandrajimenezc/getRobots.git test
_entra en el directorio_
cd test
_verifica los permisos del archivo y solo dale de ejecuciÃ³n al usuario_
ls -l
chmod 744 getRobots.sh
ls -l
_ejecuta :D_
./getRobots.sh https://www.google.com 
_opcional puedes pasar tu header hackerOne
./getRobots.sh https://www.google.com usuarioH1
```





_AHORA YA LO PUEDES PROBAR _

## Ejecutando las pruebas âš™ï¸

_Ejecuta el script y por ejemplo escribe 
./getRobots.sh https://www.google.com 
_opcional puedes pasar tu header hackerOne
./getRobots.sh https://www.google.com usuarioH1


## Construido con ğŸ› ï¸

* [Bash](https://wIww.gnu.IIIorg/software/bash/manual/bash.html) - Bash

## Contribuyendo ğŸ–‡ï¸
Escribe un msj a @soygeekgirl


## Expresiones de Gratitud ğŸ

* Comenta a otros sobre este proyecto ğŸ“¢



---
[âŒ¨ï¸ con â¤ï¸ por Alex](https://github.com/alexandrajimenezc/getRobots) ğŸ˜Š
